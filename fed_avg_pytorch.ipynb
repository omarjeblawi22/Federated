{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phywThlnXjeO"
      },
      "source": [
        "# **Import necessary libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BsPuCZ7gk8LJ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import copy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2cR9yLbX4ZA"
      },
      "source": [
        "# **Define variables for optimizer function and data processing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zAa61x5TlDj9"
      },
      "outputs": [],
      "source": [
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define variables for optimizer function and data processing\n",
        "NUMOFCLIENTS = 10\n",
        "SELECT_CLIENTS = 0.5\n",
        "EPOCHS = 5\n",
        "CLIENT_EPOCHS = 5\n",
        "BATCH_SIZE = 10\n",
        "DROP_RATE = 0\n",
        "\n",
        "# Model config\n",
        "LOSS = nn.CrossEntropyLoss()\n",
        "NUMOFCLASSES = 10\n",
        "lr = 0.0025\n",
        "OPTIMIZER = optim.SGD  # You can customize the optimizer later if needed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1NpcgxkYRo0"
      },
      "source": [
        "## Writes the data into a csv file\n",
        "\n",
        "### Part of preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLTRdwvOm0dn"
      },
      "outputs": [],
      "source": [
        "def write_csv(method_name, list):\n",
        "    file_name = '{name}_CIFAR10_randomDrop_{drop}%_output_C_{c}_LR_{lr}_CLI_{cli}_CLI_EPOCHS_{cli_epoch}_TOTAL_EPOCHS_{epochs}_BATCH_{batch}.csv'\n",
        "    file_name = file_name.format(folder=\"origin_drop\",drop=DROP_RATE, name=method_name, c=SELECT_CLIENTS, lr=lr, cli=NUMOFCLIENTS, cli_epoch=CLIENT_EPOCHS, epochs=EPOCHS, batch=BATCH_SIZE)\n",
        "    f = open(file_name, 'w', encoding='utf-8', newline='')\n",
        "    wr = csv.writer(f)\n",
        "\n",
        "    for l in list:\n",
        "        wr.writerow(l)\n",
        "    f.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldqD7NNTYhE7"
      },
      "source": [
        "## **Continue data preprocessing**\n",
        "\n",
        "Prepare training and testing sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cWckmCjIm32Z"
      },
      "outputs": [],
      "source": [
        "def load_dataset():\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "    ])\n",
        "\n",
        "    train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "    test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    return train_loader, test_loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-y0YZaFZDNj"
      },
      "source": [
        "## **Instantiate Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1oOq75xYm7X6"
      },
      "outputs": [],
      "source": [
        "class FlModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FlModel, self).__init__()\n",
        "        # Define the model architecture based on the one you built in the previous section\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=5, padding=2)\n",
        "        self.conv2 = nn.Conv2d(32, 32, kernel_size=5, padding=2)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "        self.dropout1 = nn.Dropout2d(0.2)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(32, 64, kernel_size=5, padding=2)\n",
        "        self.conv4 = nn.Conv2d(64, 64, kernel_size=5, padding=2)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "        self.dropout2 = nn.Dropout2d(0.2)\n",
        "\n",
        "        self.fc1 = nn.Linear(64 * 8 * 8, 512)\n",
        "        self.dropout3 = nn.Dropout(0.2)\n",
        "        self.fc2 = nn.Linear(512, NUMOFCLASSES)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Define the forward pass here\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool1(x)\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = self.pool2(x)\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        x = x.view(-1, 64 * 8 * 8)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout3(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return F.softmax(x, dim=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TxXVq7GZJls"
      },
      "source": [
        "## **Splits the training and testing sets among the available clients**\n",
        "\n",
        "Decentralized learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YaVmdBsgm9pm"
      },
      "outputs": [],
      "source": [
        "def client_data_config(train_loader):\n",
        "    client_data = [() for _ in range(NUMOFCLIENTS)]\n",
        "    num_of_each_dataset = len(train_loader.dataset) // NUMOFCLIENTS\n",
        "\n",
        "    for i in range(NUMOFCLIENTS):\n",
        "        split_data_index = random.sample(range(len(train_loader.dataset)), num_of_each_dataset)\n",
        "        new_x_train = torch.stack([train_loader.dataset[k][0] for k in split_data_index])\n",
        "        new_y_train = torch.tensor([train_loader.dataset[k][1] for k in split_data_index])\n",
        "\n",
        "        client_data[i] = (new_x_train, new_y_train)\n",
        "\n",
        "    return client_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAqIrkVBZtLN"
      },
      "source": [
        "## **Implementation of Federated Average Algorithm**\n",
        "\n",
        "Computation of average weights of a model across clients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "baS__gPKnAQo"
      },
      "outputs": [],
      "source": [
        "def fedAVG(server_state_dict, client_state_dicts):\n",
        "    avg_state_dict = copy.deepcopy(server_state_dict)\n",
        "\n",
        "    if len(client_state_dicts) > 0:\n",
        "        for key in avg_state_dict.keys():\n",
        "            for client_state_dict in client_state_dicts:\n",
        "                avg_state_dict[key] += client_state_dict[key]\n",
        "\n",
        "            avg_state_dict[key] /= len(client_state_dicts)\n",
        "\n",
        "    return avg_state_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g48APLt_y4tm"
      },
      "source": [
        "Accuracy Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "px_KO7jfy4Bu"
      },
      "outputs": [],
      "source": [
        "def calculate_accuracy(model, data_loader):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in data_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            # Get predicted labels\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "            # Update counts\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = correct / total\n",
        "    return accuracy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rFWU4lfaD-i"
      },
      "source": [
        "## **Updates the client models by running them through the existent models assigned to the clients**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fSMr4jdUnDuJ"
      },
      "outputs": [],
      "source": [
        "def client_update(index, client, now_epoch, avg_state_dict, train_loader):\n",
        "    print(f\"client {index + 1}/{len(selected_model)} fitting\")\n",
        "\n",
        "    if now_epoch != 0:\n",
        "        client.load_state_dict(avg_state_dict)\n",
        "\n",
        "    # Define the optimizer and other necessary settings\n",
        "    optimizer = OPTIMIZER(client.parameters(), lr=lr)\n",
        "\n",
        "    for epoch in range(CLIENT_EPOCHS):\n",
        "        # Your training loop here\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # Zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = client(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backward pass and optimization\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Print loss for each iteration\n",
        "            # print(f\"Client {index + 1}/{len(selected_model)} - Epoch {now_epoch + 1}/{EPOCHS} - Loss: {loss.item()}\")\n",
        "\n",
        "            accuracy = calculate_accuracy(client, train_loader)\n",
        "            client.accuracy = accuracy  # Store accuracy as an attribute\n",
        "            print(f\"Client {index + 1}/{int(NUMOFCLIENTS * SELECT_CLIENTS)} - Epoch {epoch + 1}/{CLIENT_EPOCHS} - Loss: {loss.item():.4f}, Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "    return client.state_dict()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUT4cKkyaiQq"
      },
      "source": [
        "## **Runs federated learning code on client datasets, displaying epochs, weighted average, loss, and accuracy.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6sQR51fnEk9",
        "outputId": "a10ea183-eac1-4dbf-fe68-3fd9a3d06294"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170498071/170498071 [00:02<00:00, 60275243.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "client 1/5 fitting\n",
            "Client 1/5 - Epoch 1/5 - Loss: 2.3018, Accuracy: 0.1170\n",
            "Client 1/5 - Epoch 1/5 - Loss: 2.3015, Accuracy: 0.1167\n",
            "Client 1/5 - Epoch 1/5 - Loss: 2.3035, Accuracy: 0.1170\n",
            "Client 1/5 - Epoch 1/5 - Loss: 2.3023, Accuracy: 0.1171\n",
            "Client 1/5 - Epoch 1/5 - Loss: 2.3017, Accuracy: 0.1172\n",
            "Client 1/5 - Epoch 1/5 - Loss: 2.3023, Accuracy: 0.1170\n",
            "Client 1/5 - Epoch 1/5 - Loss: 2.3021, Accuracy: 0.1173\n",
            "Client 1/5 - Epoch 1/5 - Loss: 2.3029, Accuracy: 0.1172\n",
            "Client 1/5 - Epoch 1/5 - Loss: 2.3021, Accuracy: 0.1169\n",
            "Client 1/5 - Epoch 1/5 - Loss: 2.3021, Accuracy: 0.1167\n",
            "Client 1/5 - Epoch 1/5 - Loss: 2.3036, Accuracy: 0.1168\n",
            "Client 1/5 - Epoch 1/5 - Loss: 2.3041, Accuracy: 0.1169\n",
            "Client 1/5 - Epoch 1/5 - Loss: 2.3026, Accuracy: 0.1171\n",
            "Client 1/5 - Epoch 1/5 - Loss: 2.3017, Accuracy: 0.1170\n",
            "Client 1/5 - Epoch 1/5 - Loss: 2.3018, Accuracy: 0.1170\n",
            "Client 1/5 - Epoch 1/5 - Loss: 2.3021, Accuracy: 0.1169\n",
            "Client 1/5 - Epoch 1/5 - Loss: 2.3022, Accuracy: 0.1172\n",
            "Client 1/5 - Epoch 1/5 - Loss: 2.3015, Accuracy: 0.1173\n",
            "Client 1/5 - Epoch 1/5 - Loss: 2.3018, Accuracy: 0.1172\n",
            "Client 1/5 - Epoch 1/5 - Loss: 2.3018, Accuracy: 0.1174\n",
            "Client 1/5 - Epoch 1/5 - Loss: 2.3026, Accuracy: 0.1174\n",
            "Client 1/5 - Epoch 1/5 - Loss: 2.3026, Accuracy: 0.1174\n",
            "Client 1/5 - Epoch 1/5 - Loss: 2.3027, Accuracy: 0.1175\n",
            "Client 1/5 - Epoch 1/5 - Loss: 2.3029, Accuracy: 0.1175\n",
            "Client 1/5 - Epoch 1/5 - Loss: 2.3027, Accuracy: 0.1175\n",
            "Client 1/5 - Epoch 1/5 - Loss: 2.3026, Accuracy: 0.1175\n",
            "Client 1/5 - Epoch 1/5 - Loss: 2.3031, Accuracy: 0.1176\n",
            "Client 1/5 - Epoch 1/5 - Loss: 2.3025, Accuracy: 0.1176\n",
            "Client 1/5 - Epoch 1/5 - Loss: 2.3032, Accuracy: 0.1175\n",
            "Client 1/5 - Epoch 1/5 - Loss: 2.3024, Accuracy: 0.1174\n",
            "Client 1/5 - Epoch 1/5 - Loss: 2.3027, Accuracy: 0.1175\n",
            "Client 1/5 - Epoch 1/5 - Loss: 2.3029, Accuracy: 0.1175\n",
            "Client 1/5 - Epoch 1/5 - Loss: 2.3027, Accuracy: 0.1171\n",
            "Client 1/5 - Epoch 1/5 - Loss: 2.3033, Accuracy: 0.1173\n",
            "Client 1/5 - Epoch 1/5 - Loss: 2.3025, Accuracy: 0.1176\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Load dataset and create DataLoader\n",
        "    train_loader, test_loader = load_dataset()\n",
        "\n",
        "    # Instantiate the server model and move it to the appropriate device (GPU if available)\n",
        "    server_model = FlModel().to(device)\n",
        "\n",
        "    # Generate client data configurations\n",
        "    client_data = client_data_config(train_loader)\n",
        "\n",
        "    # Instantiate client models and move them to the appropriate device\n",
        "    fl_model = [FlModel().to(device) for _ in range(NUMOFCLIENTS)]\n",
        "\n",
        "    # Initialize the state dictionary for FedAvg\n",
        "    avg_state_dict = copy.deepcopy(server_model.state_dict())\n",
        "\n",
        "    # List to store evaluation accuracy for each epoch\n",
        "    server_evaluate_acc = []\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(EPOCHS):\n",
        "        client_state_dicts = []\n",
        "\n",
        "        # Randomly select a subset of clients for this round\n",
        "        selected_num = int(max(NUMOFCLIENTS * SELECT_CLIENTS, 1))\n",
        "        split_data_index = random.sample(range(NUMOFCLIENTS), selected_num)\n",
        "        selected_model = [fl_model[k] for k in split_data_index]\n",
        "\n",
        "        # Perform client updates and gather client states\n",
        "        for index, client in enumerate(selected_model):\n",
        "            client_state_dict = client_update(index, client, epoch, avg_state_dict, train_loader)\n",
        "            client_state_dicts.append(client_state_dict)\n",
        "\n",
        "        # Aggregate client states using FedAVG\n",
        "        avg_state_dict = fedAVG(avg_state_dict, client_state_dicts)\n",
        "\n",
        "        # Update the server model with the aggregated state\n",
        "        server_model.load_state_dict(avg_state_dict)\n",
        "\n",
        "    # Evaluate the server model on the test set\n",
        "    server_model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = server_model(inputs)\n",
        "\n",
        "            # Get predicted labels\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "            # Update counts\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    # Calculate and print accuracy\n",
        "    accuracy = correct / total\n",
        "    print(f\"Epoch {epoch + 1}/{EPOCHS} - Accuracy on test set: {accuracy}\")\n",
        "\n",
        "    # Save accuracy for logging or further analysis\n",
        "    server_evaluate_acc.append(accuracy)\n",
        "\n",
        "    # Write the evaluation results to a CSV file\n",
        "    write_csv(\"FedAvg\", server_evaluate_acc)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}